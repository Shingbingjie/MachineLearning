#Neural Networks for Handwritten Digit Recognition, Multiclass


In this exercise, you will use a neural network to recognize hand-written digits from 0 to 9. The exercise involves using a multiclass neural network with the Rectified Linear Unit (ReLU) activation function and the softmax function for generating a probability distribution. The dataset used for training and testing consists of 5000 examples of handwritten digits represented as 20x20 grayscale images. The goal is to build a three-layer neural network using the Keras Sequential model and Dense layers with ReLU activation to accurately classify the digits. The model will be trained using the SparseCategoricalCrossentropy loss function and the Adam optimizer for a specified number of epochs. The progress of the training will be monitored by tracking the loss. Finally, the trained model will be used to make predictions on new images of digits.
